{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3125fa76",
   "metadata": {},
   "source": [
    "Iris with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91179a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 모델 정의\n",
    "class IrisModel:\n",
    "    def __init__(self) :\n",
    "        # 가중치와 편향 초기화\n",
    "        self.W1 = tf.Variable(tf.random.normal([4, 50]), dtype=tf.float32)\n",
    "        self.b1 = tf.Variable(tf.zeros([50]), dtype=tf.float32)\n",
    "        self.W2 = tf.Variable(tf.random.normal([50, 30]), dtype=tf.float32)\n",
    "        self.b2 = tf.Variable(tf.zeros([30]), dtype=tf.float32)\n",
    "        self.W3 = tf.Variable(tf.random.normal([30, 3]), dtype=tf.float32)\n",
    "        self.b3 = tf.Variable(tf.zeros([3]), dtype=tf.float32)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # 순전파 : 입력 -> 히든레이어 1 -> 히든레이어 2 -> 출력\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = tf.nn.sigmoid(tf.matmul(x, self.W1) + self.b1)\n",
    "        x = tf.nn.sigmoid(tf.matmul(x, self.W2) + self.b2)\n",
    "        return tf.nn.softmax(tf.matmul(x, self.W3) + self.b3)\n",
    "    \n",
    "# 손실 함수 정의 (CrossEntropy)\n",
    "def loss_fn(model, inputs, labels):\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    predictions = model(inputs)\n",
    "    labels_one_hot = tf.one_hot(labels, depth=3) # one-hot 인코딩\n",
    "    loss = tf.reduce_mean(tf.losses.categorical_crossentropy(labels_one_hot, predictions))\n",
    "    return loss\n",
    "\n",
    "# 옵티마이저 설정 (Adam)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_step(model, inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, inputs, labels) # 손실 계산\n",
    "    \n",
    "    gradients = tape.gradient(loss, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3]) # 그래디언트 계산\n",
    "    optimizer.apply_gradients(zip(gradients, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3])) # 가중치 업데이트\n",
    "    return loss\n",
    "    \n",
    "# 정확도 계산 함수\n",
    "def compute_accracy(model, inputs, labels):\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    predictions = model(inputs)\n",
    "    predicted_class = tf.argmax(predictions, axis=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_class, labels), tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "# 데이터 로드\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# 데이터를 텐서로 변환\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.int64)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45154b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss : 1.3442, Accuracy : 0.3524\n",
      "Epoch 6/40, Loss : 0.9844, Accuracy : 0.5905\n",
      "Epoch 11/40, Loss : 0.6092, Accuracy : 0.6190\n",
      "Epoch 16/40, Loss : 0.4308, Accuracy : 0.9619\n",
      "Epoch 21/40, Loss : 0.3579, Accuracy : 0.9619\n",
      "Epoch 26/40, Loss : 0.3099, Accuracy : 0.9714\n",
      "Epoch 31/40, Loss : 0.2830, Accuracy : 0.9714\n",
      "Epoch 36/40, Loss : 0.2660, Accuracy : 0.9714\n",
      "Test Accuracy : 0.9778\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = IrisModel()\n",
    "\n",
    "# 학습\n",
    "num_epochs = 40\n",
    "batch_size = 16\n",
    "num_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        X_batch = X_train[start_idx:end_idx]\n",
    "        y_batch = y_train[start_idx:end_idx]\n",
    "        \n",
    "        loss = train_step(model, X_batch, y_batch) # 학습 단계\n",
    "        \n",
    "    if epoch % 5 == 0: # 매 5 에포크마다 정확도 출력\n",
    "        train_accuracy = compute_accracy(model, X_train, y_train)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss : {loss:.4f}, Accuracy : {train_accuracy:.4f}')\n",
    "        \n",
    "\n",
    "# 평가\n",
    "test_accuracy = compute_accracy(model, X_test, y_test)\n",
    "print(f'Test Accuracy : {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
