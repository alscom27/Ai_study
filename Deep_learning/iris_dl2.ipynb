{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd59b5a",
   "metadata": {},
   "source": [
    "iris dl 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9830493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">183</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m150\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │        \u001b[38;5;34m100\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m50\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m183\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">483</span> (1.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m483\u001b[0m (1.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">483</span> (1.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m483\u001b[0m (1.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import concatenate, Activation\n",
    "\n",
    "input = Input(shape=(4,))\n",
    "dense1 = Dense(30, activation='relu')(input)\n",
    "dense2 = Dense(20, activation='relu')(input)\n",
    "dense3 = Dense(10, activation='relu')(input)\n",
    "x = concatenate([dense1, dense2, dense3])\n",
    "output = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71f931c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3000 - loss: 2.6687  \n",
      "Epoch 2/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2677 - loss: 2.3746 \n",
      "Epoch 3/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2907 - loss: 1.9732 \n",
      "Epoch 4/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2917 - loss: 1.4478 \n",
      "Epoch 5/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4845 - loss: 1.0787 \n",
      "Epoch 6/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6215 - loss: 0.9083 \n",
      "Epoch 7/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6385 - loss: 0.7663 \n",
      "Epoch 8/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6864 - loss: 0.7249 \n",
      "Epoch 9/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7177 - loss: 0.6952 \n",
      "Epoch 10/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6614 - loss: 0.7380 \n",
      "Epoch 11/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6833 - loss: 0.7049 \n",
      "Epoch 12/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6739 - loss: 0.6917 \n",
      "Epoch 13/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7104 - loss: 0.6345 \n",
      "Epoch 14/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6698 - loss: 0.6427 \n",
      "Epoch 15/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7021 - loss: 0.6038 \n",
      "Epoch 16/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6812 - loss: 0.5956 \n",
      "Epoch 17/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7031 - loss: 0.5807 \n",
      "Epoch 18/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.5584 \n",
      "Epoch 19/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7690 - loss: 0.5403 \n",
      "Epoch 20/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.5491 \n",
      "Epoch 21/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 0.5270 \n",
      "Epoch 22/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5265 \n",
      "Epoch 23/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7738 - loss: 0.5238 \n",
      "Epoch 24/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7971 - loss: 0.5114 \n",
      "Epoch 25/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.5217 \n",
      "Epoch 26/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.5086 \n",
      "Epoch 27/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8238 - loss: 0.4861 \n",
      "Epoch 28/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.4968 \n",
      "Epoch 29/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 0.4973 \n",
      "Epoch 30/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7995 - loss: 0.4806\n",
      "Epoch 31/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.4736 \n",
      "Epoch 32/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.4544 \n",
      "Epoch 33/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7832 - loss: 0.4530 \n",
      "Epoch 34/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.4480 \n",
      "Epoch 35/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8915 - loss: 0.4038 \n",
      "Epoch 36/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8848 - loss: 0.4508 \n",
      "Epoch 37/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.4310 \n",
      "Epoch 38/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8696 - loss: 0.4253 \n",
      "Epoch 39/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.4048 \n",
      "Epoch 40/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8984 - loss: 0.4042 \n",
      "Epoch 41/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.4121 \n",
      "Epoch 42/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.4097 \n",
      "Epoch 43/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.9244 - loss: 0.4055\n",
      "Epoch 44/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.4068\n",
      "Epoch 45/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.3805 \n",
      "Epoch 46/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.3982 \n",
      "Epoch 47/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.3827 \n",
      "Epoch 48/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.3722 \n",
      "Epoch 49/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.3838 \n",
      "Epoch 50/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.3652 \n",
      "Epoch 51/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.3680 \n",
      "Epoch 52/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9146 - loss: 0.3773 \n",
      "Epoch 53/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.3531 \n",
      "Epoch 54/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.3694 \n",
      "Epoch 55/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.3638 \n",
      "Epoch 56/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.3696 \n",
      "Epoch 57/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.3463 \n",
      "Epoch 58/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.3483 \n",
      "Epoch 59/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.3438 \n",
      "Epoch 60/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.3479 \n",
      "Epoch 61/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.3350 \n",
      "Epoch 62/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9553 - loss: 0.3428 \n",
      "Epoch 63/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9327 - loss: 0.3199 \n",
      "Epoch 64/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9275 - loss: 0.3303 \n",
      "Epoch 65/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9303 - loss: 0.3392\n",
      "Epoch 66/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.3071 \n",
      "Epoch 67/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.3058 \n",
      "Epoch 68/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.3119 \n",
      "Epoch 69/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.3068 \n",
      "Epoch 70/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.2975 \n",
      "Epoch 71/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.2791 \n",
      "Epoch 72/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.3161 \n",
      "Epoch 73/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.2861 \n",
      "Epoch 74/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.2976 \n",
      "Epoch 75/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.3057\n",
      "Epoch 76/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.2805 \n",
      "Epoch 77/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.2881 \n",
      "Epoch 78/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9386 - loss: 0.2678 \n",
      "Epoch 79/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.2815 \n",
      "Epoch 80/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.2885 \n",
      "Epoch 81/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.2941 \n",
      "Epoch 82/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.2699\n",
      "Epoch 83/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.2691 \n",
      "Epoch 84/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.2797 \n",
      "Epoch 85/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.2691 \n",
      "Epoch 86/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.2649 \n",
      "Epoch 87/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 0.2598 \n",
      "Epoch 88/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.2525\n",
      "Epoch 89/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9549 - loss: 0.2559 \n",
      "Epoch 90/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.2493\n",
      "Epoch 91/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.2548 \n",
      "Epoch 92/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.2448\n",
      "Epoch 93/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.2437 \n",
      "Epoch 94/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9782 - loss: 0.2372 \n",
      "Epoch 95/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.2429 \n",
      "Epoch 96/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.2406 \n",
      "Epoch 97/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.2351 \n",
      "Epoch 98/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9629 - loss: 0.2416 \n",
      "Epoch 99/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.2331 \n",
      "Epoch 100/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9636 - loss: 0.2445 \n",
      "Epoch 101/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.2381 \n",
      "Epoch 102/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9566 - loss: 0.2326 \n",
      "Epoch 103/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9608 - loss: 0.2218\n",
      "Epoch 104/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.2291 \n",
      "Epoch 105/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.2154 \n",
      "Epoch 106/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.2302 \n",
      "Epoch 107/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.2244 \n",
      "Epoch 108/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.2258 \n",
      "Epoch 109/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.2154 \n",
      "Epoch 110/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9719 - loss: 0.2128 \n",
      "Epoch 111/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.2176 \n",
      "Epoch 112/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.2133 \n",
      "Epoch 113/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.2098 \n",
      "Epoch 114/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.2137\n",
      "Epoch 115/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.2031 \n",
      "Epoch 116/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.2188 \n",
      "Epoch 117/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.2013 \n",
      "Epoch 118/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.1973 \n",
      "Epoch 119/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9657 - loss: 0.1990\n",
      "Epoch 120/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.2095 \n",
      "Epoch 121/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.2044 \n",
      "Epoch 122/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.2091\n",
      "Epoch 123/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.2032 \n",
      "Epoch 124/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.9761 - loss: 0.1920\n",
      "Epoch 125/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9636 - loss: 0.2010\n",
      "Epoch 126/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.1985 \n",
      "Epoch 127/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.1771 \n",
      "Epoch 128/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1970 \n",
      "Epoch 129/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1832 \n",
      "Epoch 130/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.1809\n",
      "Epoch 131/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.1803 \n",
      "Epoch 132/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.1995 \n",
      "Epoch 133/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.1833 \n",
      "Epoch 134/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.1671 \n",
      "Epoch 135/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.1779 \n",
      "Epoch 136/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.1900 \n",
      "Epoch 137/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.1857 \n",
      "Epoch 138/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.1889 \n",
      "Epoch 139/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.1792\n",
      "Epoch 140/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.1687 \n",
      "Epoch 141/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.1693 \n",
      "Epoch 142/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9542 - loss: 0.1882 \n",
      "Epoch 143/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.1629 \n",
      "Epoch 144/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9691 - loss: 0.1705 \n",
      "Epoch 145/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.1637 \n",
      "Epoch 146/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.1707 \n",
      "Epoch 147/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.1618 \n",
      "Epoch 148/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1746 \n",
      "Epoch 149/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.1823 \n",
      "Epoch 150/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1651 \n",
      "Epoch 151/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1627 \n",
      "Epoch 152/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.1527 \n",
      "Epoch 153/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.1459\n",
      "Epoch 154/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1712 \n",
      "Epoch 155/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.1455 \n",
      "Epoch 156/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.1542 \n",
      "Epoch 157/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.1597 \n",
      "Epoch 158/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.1710 \n",
      "Epoch 159/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1656 \n",
      "Epoch 160/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27us/step - accuracy: 0.9903 - loss: 0.1615\n",
      "Epoch 161/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1567 \n",
      "Epoch 162/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1494 \n",
      "Epoch 163/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1394 \n",
      "Epoch 164/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.1571 \n",
      "Epoch 165/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.1489 \n",
      "Epoch 166/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.1591 \n",
      "Epoch 167/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.1570 \n",
      "Epoch 168/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1565 \n",
      "Epoch 169/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1679 \n",
      "Epoch 170/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.1490\n",
      "Epoch 171/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.1445\n",
      "Epoch 172/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.1310 \n",
      "Epoch 173/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1596 \n",
      "Epoch 174/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1519\n",
      "Epoch 175/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1448 \n",
      "Epoch 176/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1417 \n",
      "Epoch 177/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1550 \n",
      "Epoch 178/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1341\n",
      "Epoch 179/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1434 \n",
      "Epoch 180/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.1446 \n",
      "Epoch 181/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.1258 \n",
      "Epoch 182/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9757 - loss: 0.1388 \n",
      "Epoch 183/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9792 - loss: 0.1376\n",
      "Epoch 184/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1380\n",
      "Epoch 185/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.1358 \n",
      "Epoch 186/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.1310 \n",
      "Epoch 187/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.1461 \n",
      "Epoch 188/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.1395 \n",
      "Epoch 189/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.1334 \n",
      "Epoch 190/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.1266 \n",
      "Epoch 191/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.1343\n",
      "Epoch 192/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1406 \n",
      "Epoch 193/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.1328 \n",
      "Epoch 194/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1385 \n",
      "Epoch 195/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.1292 \n",
      "Epoch 196/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1336 \n",
      "Epoch 197/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.1281 \n",
      "Epoch 198/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.1321 \n",
      "Epoch 199/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.1348 \n",
      "Epoch 200/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1314 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14233241975307465, 1.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "model.fit(X_train, y_train, epochs=200)\n",
    "\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "# predictions = model.predict(x_new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cd997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "# 함수형 모델 저장\n",
    "model.save(\"my_model1.keras\")\n",
    "print(\"모델 저장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4394875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m620\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,013</span> (3.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,013\u001b[0m (3.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,013</span> (3.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,013\u001b[0m (3.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Input(shape=(4,)))\n",
    "model2.add(Dense(30, activation='sigmoid'))\n",
    "model2.add(Dense(20, activation='sigmoid'))\n",
    "model2.add(Dense(10, activation='sigmoid'))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4c2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2896 - loss: 1.6064  \n",
      "Epoch 2/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3167 - loss: 1.5004 \n",
      "Epoch 3/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3240 - loss: 1.4489 \n",
      "Epoch 4/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2979 - loss: 1.4579 \n",
      "Epoch 5/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3000 - loss: 1.4091 \n",
      "Epoch 6/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3282 - loss: 1.3428 \n",
      "Epoch 7/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3625 - loss: 1.2769 \n",
      "Epoch 8/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2896 - loss: 1.3312 \n",
      "Epoch 9/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3448 - loss: 1.2365 \n",
      "Epoch 10/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3084 - loss: 1.2586 \n",
      "Epoch 11/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3073 - loss: 1.2462 \n",
      "Epoch 12/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3032 - loss: 1.2433 \n",
      "Epoch 13/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2688 - loss: 1.2364 \n",
      "Epoch 14/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3167 - loss: 1.1832\n",
      "Epoch 15/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3282 - loss: 1.1683 \n",
      "Epoch 16/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2844 - loss: 1.1809 \n",
      "Epoch 17/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3000 - loss: 1.1572 \n",
      "Epoch 18/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3240 - loss: 1.1366 \n",
      "Epoch 19/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 1.1709 \n",
      "Epoch 20/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3323 - loss: 1.1309 \n",
      "Epoch 21/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2979 - loss: 1.1221 \n",
      "Epoch 22/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2938 - loss: 1.1235 \n",
      "Epoch 23/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2990 - loss: 1.1216 \n",
      "Epoch 24/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3115 - loss: 1.1092 \n",
      "Epoch 25/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2813 - loss: 1.1180 \n",
      "Epoch 26/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3094 - loss: 1.1045 \n",
      "Epoch 27/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3115 - loss: 1.1014 \n",
      "Epoch 28/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2854 - loss: 1.1034 \n",
      "Epoch 29/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3282 - loss: 1.0925 \n",
      "Epoch 30/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3240 - loss: 1.0905 \n",
      "Epoch 31/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2719 - loss: 1.0977 \n",
      "Epoch 32/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2948 - loss: 1.0910 \n",
      "Epoch 33/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3052 - loss: 1.0878 \n",
      "Epoch 34/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3011 - loss: 1.0863\n",
      "Epoch 35/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3052 - loss: 1.0840 \n",
      "Epoch 36/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3136 - loss: 1.0817 \n",
      "Epoch 37/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3282 - loss: 1.0793 \n",
      "Epoch 38/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3104 - loss: 1.0787 \n",
      "Epoch 39/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3236 - loss: 1.0774 \n",
      "Epoch 40/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7235 - loss: 1.0755 \n",
      "Epoch 41/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8685 - loss: 1.0736 \n",
      "Epoch 42/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 1.0720 \n",
      "Epoch 43/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 1.0692 \n",
      "Epoch 44/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6781 - loss: 1.0685 \n",
      "Epoch 45/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 1.0643 \n",
      "Epoch 46/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7166 - loss: 1.0602 \n",
      "Epoch 47/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7052 - loss: 1.0598 \n",
      "Epoch 48/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6937 - loss: 1.0585 \n",
      "Epoch 49/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 1.0535 \n",
      "Epoch 50/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7291 - loss: 1.0491 \n",
      "Epoch 51/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.0518\n",
      "Epoch 52/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7000 - loss: 1.0459\n",
      "Epoch 53/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6885 - loss: 1.0441 \n",
      "Epoch 54/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 1.0404 \n",
      "Epoch 55/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6666 - loss: 1.0391 \n",
      "Epoch 56/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6791 - loss: 1.0338 \n",
      "Epoch 57/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7010 - loss: 1.0264 \n",
      "Epoch 58/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 1.0149 \n",
      "Epoch 59/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6885 - loss: 1.0181 \n",
      "Epoch 60/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 1.0134 \n",
      "Epoch 61/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7104 - loss: 1.0051 \n",
      "Epoch 62/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.7041 - loss: 0.9993\n",
      "Epoch 63/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6750 - loss: 0.9974 \n",
      "Epoch 64/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6718 - loss: 0.9934\n",
      "Epoch 65/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 0.9826 \n",
      "Epoch 66/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6771 - loss: 0.9749 \n",
      "Epoch 67/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6896 - loss: 0.9709 \n",
      "Epoch 68/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6885 - loss: 0.9626 \n",
      "Epoch 69/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7021 - loss: 0.9499 \n",
      "Epoch 70/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6916 - loss: 0.9441 \n",
      "Epoch 71/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7146 - loss: 0.9316\n",
      "Epoch 72/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.9281 \n",
      "Epoch 73/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 0.9095 \n",
      "Epoch 74/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7396 - loss: 0.8944 \n",
      "Epoch 75/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6781 - loss: 0.9063 \n",
      "Epoch 76/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6896 - loss: 0.8943 \n",
      "Epoch 77/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6965 - loss: 0.8866\n",
      "Epoch 78/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7097 - loss: 0.8743 \n",
      "Epoch 79/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 0.8760 \n",
      "Epoch 80/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6896 - loss: 0.8569 \n",
      "Epoch 81/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6771 - loss: 0.8541 \n",
      "Epoch 82/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 0.8339 \n",
      "Epoch 83/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7125 - loss: 0.8231 \n",
      "Epoch 84/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7038 - loss: 0.8199 \n",
      "Epoch 85/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6965 - loss: 0.8146 \n",
      "Epoch 86/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7007 - loss: 0.7987 \n",
      "Epoch 87/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 0.7860 \n",
      "Epoch 88/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6882 - loss: 0.7833 \n",
      "Epoch 89/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6986 - loss: 0.7715 \n",
      "Epoch 90/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6937 - loss: 0.7621 \n",
      "Epoch 91/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7073 - loss: 0.7501 \n",
      "Epoch 92/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7083 - loss: 0.7391 \n",
      "Epoch 93/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.7337 \n",
      "Epoch 94/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6864 - loss: 0.7351 \n",
      "Epoch 95/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7277 - loss: 0.7181 \n",
      "Epoch 96/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.7126 \n",
      "Epoch 97/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7208 - loss: 0.7141\n",
      "Epoch 98/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7527 - loss: 0.6897 \n",
      "Epoch 99/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7378 - loss: 0.6967\n",
      "Epoch 100/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.6954 \n",
      "Epoch 101/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 0.6900 \n",
      "Epoch 102/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.6809 \n",
      "Epoch 103/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - loss: 0.6504 \n",
      "Epoch 104/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.6758 \n",
      "Epoch 105/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.6472 \n",
      "Epoch 106/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7558 - loss: 0.6598 \n",
      "Epoch 107/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.6344 \n",
      "Epoch 108/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 0.6455 \n",
      "Epoch 109/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.6470 \n",
      "Epoch 110/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7409 - loss: 0.6478 \n",
      "Epoch 111/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.6229\n",
      "Epoch 112/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.6074 \n",
      "Epoch 113/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7784 - loss: 0.6084 \n",
      "Epoch 114/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.6087 \n",
      "Epoch 115/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7738 - loss: 0.6276 \n",
      "Epoch 116/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.5975 \n",
      "Epoch 117/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.5954 \n",
      "Epoch 118/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 0.5951 \n",
      "Epoch 119/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8342 - loss: 0.6061 \n",
      "Epoch 120/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.5788 \n",
      "Epoch 121/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.5867 \n",
      "Epoch 122/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.5811 \n",
      "Epoch 123/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8144 - loss: 0.5699 \n",
      "Epoch 124/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8182 - loss: 0.5747 \n",
      "Epoch 125/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8235 - loss: 0.5645\n",
      "Epoch 126/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.5587 \n",
      "Epoch 127/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.5536 \n",
      "Epoch 128/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8130 - loss: 0.5553\n",
      "Epoch 129/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8602 - loss: 0.5270 \n",
      "Epoch 130/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.5506 \n",
      "Epoch 131/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8404 - loss: 0.5571 \n",
      "Epoch 132/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.5206 \n",
      "Epoch 133/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.5239 \n",
      "Epoch 134/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.5156 \n",
      "Epoch 135/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8977 - loss: 0.5175 \n",
      "Epoch 136/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9116 - loss: 0.5113\n",
      "Epoch 137/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.4960 \n",
      "Epoch 138/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8925 - loss: 0.5084\n",
      "Epoch 139/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.5046 \n",
      "Epoch 140/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.4941 \n",
      "Epoch 141/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9178 - loss: 0.4962 \n",
      "Epoch 142/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.9168 - loss: 0.5025\n",
      "Epoch 143/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9209 - loss: 0.4748\n",
      "Epoch 144/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.4684\n",
      "Epoch 145/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9098 - loss: 0.4965\n",
      "Epoch 146/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.4800 \n",
      "Epoch 147/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8963 - loss: 0.4700\n",
      "Epoch 148/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.8817 - loss: 0.4850\n",
      "Epoch 149/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.4617 \n",
      "Epoch 150/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.4641 \n",
      "Epoch 151/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 0.4485 \n",
      "Epoch 152/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.4661 \n",
      "Epoch 153/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.4460 \n",
      "Epoch 154/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.4695 \n",
      "Epoch 155/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.4442 \n",
      "Epoch 156/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.4496 \n",
      "Epoch 157/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.4381 \n",
      "Epoch 158/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.4151 \n",
      "Epoch 159/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.4409\n",
      "Epoch 160/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.4364 \n",
      "Epoch 161/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9431 - loss: 0.4176 \n",
      "Epoch 162/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.4301 \n",
      "Epoch 163/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.4304 \n",
      "Epoch 164/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9299 - loss: 0.4361 \n",
      "Epoch 165/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9476 - loss: 0.4281\n",
      "Epoch 166/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.4147 \n",
      "Epoch 167/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.4100 \n",
      "Epoch 168/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.4000 \n",
      "Epoch 169/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.4125 \n",
      "Epoch 170/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.4027 \n",
      "Epoch 171/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9639 - loss: 0.3929 \n",
      "Epoch 172/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.3981 \n",
      "Epoch 173/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.3974 \n",
      "Epoch 174/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.3998 \n",
      "Epoch 175/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9712 - loss: 0.3814\n",
      "Epoch 176/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.3659 \n",
      "Epoch 177/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.3786 \n",
      "Epoch 178/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.3798 \n",
      "Epoch 179/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.3991 \n",
      "Epoch 180/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9483 - loss: 0.3770 \n",
      "Epoch 181/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9671 - loss: 0.3682 \n",
      "Epoch 182/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.3802 \n",
      "Epoch 183/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 0.3467 \n",
      "Epoch 184/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.3543 \n",
      "Epoch 185/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.3552 \n",
      "Epoch 186/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9577 - loss: 0.3724 \n",
      "Epoch 187/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9629 - loss: 0.3569 \n",
      "Epoch 188/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9483 - loss: 0.3605 \n",
      "Epoch 189/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.3621 \n",
      "Epoch 190/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.3456 \n",
      "Epoch 191/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9566 - loss: 0.3371 \n",
      "Epoch 192/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.3333 \n",
      "Epoch 193/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9639 - loss: 0.3382 \n",
      "Epoch 194/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.3186 \n",
      "Epoch 195/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.3491 \n",
      "Epoch 196/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.3364 \n",
      "Epoch 197/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9754 - loss: 0.3142 \n",
      "Epoch 198/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.3330 \n",
      "Epoch 199/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.3161 \n",
      "Epoch 200/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.3020 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9748 - loss: 0.3397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3365892469882965, 0.9777777791023254]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=1)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "model2.fit(X_train, y_train, epochs=200)\n",
    "\n",
    "model2.evaluate(X_test, y_test)\n",
    "\n",
    "# predictions = model.predict(x_new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "641fd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "# 일반 모델 저장\n",
    "model2.save(\"my_model2.keras\")\n",
    "print(\"모델 저장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84dfeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 성공적으로 로드되었습니다.\n",
      "입력 데이터 형태 : (3, 4)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "예측된 확률 분포 : \n",
      " [[9.9674451e-01 3.2518485e-03 3.5753828e-06]\n",
      " [9.9388981e-01 6.1040269e-03 6.1596152e-06]\n",
      " [9.8891175e-01 1.1072297e-02 1.5922522e-05]]\n",
      "예측된 클래스 : [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = load_model('my_model1.keras')\n",
    "# loaded_model = load_model('my_model2.keras')\n",
    "print(\"모델이 성공적으로 로드되었습니다.\")\n",
    "\n",
    "# 새로운 입력 데이터 (10개의 샘플, 각 샘플은 4개의 특성값)\n",
    "# X_new = np.array([\n",
    "#     [4.6, 3.6, 1.0, 0.2],\n",
    "#     [5.0, 3.4, 1.2, 0.3],\n",
    "#     [4.8, 3.1, 1.3, 0.2],\n",
    "    \n",
    "# ]).reshape(3, -1)\n",
    "\n",
    "X_random = np.random.rand(10, 4)  # shape: (10, 4)\n",
    "\n",
    "\n",
    "print(f\"입력 데이터 형태 : {X_new.shape}\")\n",
    "\n",
    "# 예측 수행\n",
    "predictions = loaded_model.predict(X_new)\n",
    "\n",
    "# 예측된 확률 분포 출력\n",
    "print(\"예측된 확률 분포 : \\n\", predictions)\n",
    "\n",
    "# 가장 높은 확률을 가진 클래스 선택\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 예측된 클래스 출력\n",
    "print(f\"예측된 클래스 : {predicted_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e8644e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\miniconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m620\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,013</span> (3.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,013\u001b[0m (3.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,013</span> (3.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,013\u001b[0m (3.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "예측 확률 분포:\n",
      " [[1.3374326e-04 9.9986506e-01 1.1906608e-06]\n",
      " [1.5154524e-03 9.9762183e-01 8.6275191e-04]\n",
      " [9.8445976e-01 1.2667049e-02 2.8732661e-03]\n",
      " [8.2010571e-05 1.6319681e-03 9.9828607e-01]\n",
      " [1.1757541e-03 9.9737728e-01 1.4470454e-03]\n",
      " [4.6245709e-02 9.2737341e-01 2.6380857e-02]\n",
      " [2.4253432e-02 9.7571373e-01 3.2788204e-05]\n",
      " [1.6433313e-04 2.1699853e-03 9.9766564e-01]\n",
      " [8.8049438e-07 9.9999917e-01 5.7819007e-09]\n",
      " [5.3953850e-03 9.9070603e-01 3.8986241e-03]]\n",
      "예측 클래스:\n",
      " [1 1 0 2 1 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 1. 데이터 불러오기 및 전처리\n",
    "iris = load_iris()\n",
    "X = iris.data   # (150, 4)\n",
    "y = iris.target.reshape(-1, 1)  # (150, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)  # (150, 3)\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. 모델 설계 (4 > 30 > 20 > 10 > 3)\n",
    "model = Sequential([\n",
    "    Dense(30, activation='relu', input_shape=(4,)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 3. 학습\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# 4. 새로운 샘플 10개 생성 (기존 데이터 범위 내에서 랜덤)\n",
    "X_new = np.column_stack([\n",
    "    np.random.choice(X[:, 0], 10),\n",
    "    np.random.choice(X[:, 1], 10),\n",
    "    np.random.choice(X[:, 2], 10),\n",
    "    np.random.choice(X[:, 3], 10)\n",
    "])\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# 5. 예측\n",
    "pred_probs = model.predict(X_new_scaled)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "# 6. 출력\n",
    "print(\"예측 확률 분포:\\n\", pred_probs)\n",
    "print(\"예측 클래스:\\n\", pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cabd69c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\miniconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "1번째 샘플\n",
      "예측 확률: [9.9981827e-01 1.5359762e-04 2.8101776e-05]\n",
      "예측 꽃 이름: setosa\n",
      "------------------------------\n",
      "2번째 샘플\n",
      "예측 확률: [9.9917966e-01 7.2334893e-04 9.6924741e-05]\n",
      "예측 꽃 이름: setosa\n",
      "------------------------------\n",
      "3번째 샘플\n",
      "예측 확률: [1.9871574e-04 2.7240419e-03 9.9707723e-01]\n",
      "예측 꽃 이름: virginica\n",
      "------------------------------\n",
      "4번째 샘플\n",
      "예측 확률: [0.00253714 0.98150796 0.01595487]\n",
      "예측 꽃 이름: versicolor\n",
      "------------------------------\n",
      "5번째 샘플\n",
      "예측 확률: [9.9977237e-01 2.0292640e-04 2.4630071e-05]\n",
      "예측 꽃 이름: setosa\n",
      "------------------------------\n",
      "6번째 샘플\n",
      "예측 확률: [0.0017143  0.9954157  0.00286997]\n",
      "예측 꽃 이름: versicolor\n",
      "------------------------------\n",
      "7번째 샘플\n",
      "예측 확률: [1.5783816e-04 5.9127309e-03 9.9392939e-01]\n",
      "예측 꽃 이름: virginica\n",
      "------------------------------\n",
      "8번째 샘플\n",
      "예측 확률: [9.9961567e-01 3.3578926e-04 4.8511429e-05]\n",
      "예측 꽃 이름: setosa\n",
      "------------------------------\n",
      "9번째 샘플\n",
      "예측 확률: [7.4585887e-06 4.9403381e-05 9.9994314e-01]\n",
      "예측 꽃 이름: virginica\n",
      "------------------------------\n",
      "10번째 샘플\n",
      "예측 확률: [2.212227e-04 2.631763e-03 9.971470e-01]\n",
      "예측 꽃 이름: virginica\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Iris 데이터 불러오기\n",
    "iris = load_iris()\n",
    "X = iris.data  # (150, 4)\n",
    "y = iris.target  # (150,)\n",
    "\n",
    "# 2. 훈련/테스트 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# 3. 모델 만들기 (Sequential 사용)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 클래스 3개\n",
    "\n",
    "# 4. 컴파일\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5. 학습\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "# 6. 새로운 데이터 10개\n",
    "new_data = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [4.9, 3.0, 1.4, 0.2],\n",
    "    [5.8, 2.7, 5.1, 1.9],\n",
    "    [6.0, 3.4, 4.5, 1.6],\n",
    "    [5.4, 3.9, 1.7, 0.4],\n",
    "    [6.2, 2.9, 4.3, 1.3],\n",
    "    [7.1, 3.0, 5.9, 2.1],\n",
    "    [5.0, 3.4, 1.5, 0.2],\n",
    "    [6.3, 3.3, 6.0, 2.5],\n",
    "    [5.6, 2.8, 4.9, 2.0],\n",
    "])\n",
    "\n",
    "# 7. 예측\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# 8. 예측 결과 해석\n",
    "flower = {0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"}\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_class = np.argmax(pred)\n",
    "    print(f\"{i+1}번째 샘플\")\n",
    "    print(f\"예측 확률: {pred}\")\n",
    "    print(f\"예측 꽃 이름: {flower[pred_class]}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1162fc8",
   "metadata": {},
   "source": [
    "ANN with Iris classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8c19d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9329b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 전처리\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f6bed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\miniconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2194 - loss: 1.4052 - val_accuracy: 0.2000 - val_loss: 1.4695\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2017 - loss: 1.4015 - val_accuracy: 0.2000 - val_loss: 1.4275\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2329 - loss: 1.3435 - val_accuracy: 0.2000 - val_loss: 1.3863\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2027 - loss: 1.3179 - val_accuracy: 0.2333 - val_loss: 1.3461\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2006 - loss: 1.3006 - val_accuracy: 0.2333 - val_loss: 1.3068\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1871 - loss: 1.2637 - val_accuracy: 0.2333 - val_loss: 1.2686\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1663 - loss: 1.2419 - val_accuracy: 0.2333 - val_loss: 1.2313\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2350 - loss: 1.1615 - val_accuracy: 0.2000 - val_loss: 1.1955\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1746 - loss: 1.1653 - val_accuracy: 0.2000 - val_loss: 1.1600\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1746 - loss: 1.1412 - val_accuracy: 0.2000 - val_loss: 1.1257\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2065 - loss: 1.0978 - val_accuracy: 0.2333 - val_loss: 1.0925\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2367 - loss: 1.0799 - val_accuracy: 0.2667 - val_loss: 1.0600\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3171 - loss: 1.0403 - val_accuracy: 0.3000 - val_loss: 1.0284\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3004 - loss: 1.0049 - val_accuracy: 0.3000 - val_loss: 0.9983\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3635 - loss: 0.9812 - val_accuracy: 0.4000 - val_loss: 0.9693\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4106 - loss: 0.9663 - val_accuracy: 0.5000 - val_loss: 0.9410\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4425 - loss: 0.9442 - val_accuracy: 0.5333 - val_loss: 0.9139\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4912 - loss: 0.9238 - val_accuracy: 0.5667 - val_loss: 0.8879\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5715 - loss: 0.8951 - val_accuracy: 0.5667 - val_loss: 0.8629\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6529 - loss: 0.8603 - val_accuracy: 0.5667 - val_loss: 0.8391\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6696 - loss: 0.8556 - val_accuracy: 0.7333 - val_loss: 0.8167\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6648 - loss: 0.8417 - val_accuracy: 0.7667 - val_loss: 0.7954\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6890 - loss: 0.8165 - val_accuracy: 0.7667 - val_loss: 0.7744\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7067 - loss: 0.8048 - val_accuracy: 0.8000 - val_loss: 0.7546\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7233 - loss: 0.7870 - val_accuracy: 0.8333 - val_loss: 0.7358\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6900 - loss: 0.7821 - val_accuracy: 0.8333 - val_loss: 0.7179\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7694 - loss: 0.7281 - val_accuracy: 0.8333 - val_loss: 0.7005\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7452 - loss: 0.7268 - val_accuracy: 0.8333 - val_loss: 0.6844\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7296 - loss: 0.7267 - val_accuracy: 0.8333 - val_loss: 0.6689\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6994 - loss: 0.7148 - val_accuracy: 0.8333 - val_loss: 0.6540\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7556 - loss: 0.6702 - val_accuracy: 0.8667 - val_loss: 0.6396\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7379 - loss: 0.6953 - val_accuracy: 0.9000 - val_loss: 0.6263\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6994 - loss: 0.6879 - val_accuracy: 0.9000 - val_loss: 0.6137\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7163 - loss: 0.6751 - val_accuracy: 0.9000 - val_loss: 0.6012\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7212 - loss: 0.6504 - val_accuracy: 0.9000 - val_loss: 0.5893\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7696 - loss: 0.6224 - val_accuracy: 0.9000 - val_loss: 0.5780\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7823 - loss: 0.6062 - val_accuracy: 0.9000 - val_loss: 0.5673\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7458 - loss: 0.6229 - val_accuracy: 0.9000 - val_loss: 0.5572\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7502 - loss: 0.6005 - val_accuracy: 0.9000 - val_loss: 0.5474\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7879 - loss: 0.5713 - val_accuracy: 0.9000 - val_loss: 0.5381\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7796 - loss: 0.5705 - val_accuracy: 0.9000 - val_loss: 0.5290\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7329 - loss: 0.6180 - val_accuracy: 0.9000 - val_loss: 0.5206\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7954 - loss: 0.5863 - val_accuracy: 0.9000 - val_loss: 0.5123\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7735 - loss: 0.5571 - val_accuracy: 0.9000 - val_loss: 0.5044\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7894 - loss: 0.5708 - val_accuracy: 0.9000 - val_loss: 0.4969\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7758 - loss: 0.5639 - val_accuracy: 0.9000 - val_loss: 0.4895\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8102 - loss: 0.5380 - val_accuracy: 0.9000 - val_loss: 0.4822\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7821 - loss: 0.5466 - val_accuracy: 0.9000 - val_loss: 0.4751\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7998 - loss: 0.5297 - val_accuracy: 0.9000 - val_loss: 0.4683\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 0.5473 - val_accuracy: 0.9000 - val_loss: 0.4620\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7917 - loss: 0.4982 - val_accuracy: 0.9000 - val_loss: 0.4557\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7740 - loss: 0.5337 - val_accuracy: 0.9000 - val_loss: 0.4496\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7937 - loss: 0.5084 - val_accuracy: 0.9000 - val_loss: 0.4436\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7885 - loss: 0.4953 - val_accuracy: 0.9000 - val_loss: 0.4378\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7917 - loss: 0.4902 - val_accuracy: 0.9000 - val_loss: 0.4321\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8021 - loss: 0.4814 - val_accuracy: 0.9000 - val_loss: 0.4265\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8158 - loss: 0.4745 - val_accuracy: 0.9000 - val_loss: 0.4210\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7960 - loss: 0.4653 - val_accuracy: 0.9000 - val_loss: 0.4158\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8065 - loss: 0.4683 - val_accuracy: 0.9000 - val_loss: 0.4106\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8033 - loss: 0.4531 - val_accuracy: 0.9000 - val_loss: 0.4055\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8169 - loss: 0.4364 - val_accuracy: 0.9000 - val_loss: 0.4004\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7815 - loss: 0.4729 - val_accuracy: 0.9000 - val_loss: 0.3955\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7731 - loss: 0.4658 - val_accuracy: 0.9000 - val_loss: 0.3906\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8127 - loss: 0.4565 - val_accuracy: 0.9000 - val_loss: 0.3858\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8054 - loss: 0.4458 - val_accuracy: 0.9000 - val_loss: 0.3811\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7825 - loss: 0.4780 - val_accuracy: 0.9000 - val_loss: 0.3764\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7950 - loss: 0.4547 - val_accuracy: 0.9333 - val_loss: 0.3718\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7663 - loss: 0.4744 - val_accuracy: 0.9333 - val_loss: 0.3674\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8383 - loss: 0.4083 - val_accuracy: 0.9333 - val_loss: 0.3629\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8375 - loss: 0.4064 - val_accuracy: 0.9333 - val_loss: 0.3585\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8458 - loss: 0.4061 - val_accuracy: 0.9333 - val_loss: 0.3543\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8356 - loss: 0.4194 - val_accuracy: 0.9333 - val_loss: 0.3502\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8481 - loss: 0.3971 - val_accuracy: 0.9333 - val_loss: 0.3461\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8306 - loss: 0.4198 - val_accuracy: 0.9333 - val_loss: 0.3422\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8567 - loss: 0.4084 - val_accuracy: 0.9333 - val_loss: 0.3384\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8546 - loss: 0.4033 - val_accuracy: 0.9333 - val_loss: 0.3347\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8848 - loss: 0.3753 - val_accuracy: 0.9333 - val_loss: 0.3310\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8877 - loss: 0.3804 - val_accuracy: 0.9333 - val_loss: 0.3273\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8960 - loss: 0.3685 - val_accuracy: 0.9333 - val_loss: 0.3236\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8888 - loss: 0.3827 - val_accuracy: 0.9333 - val_loss: 0.3201\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8890 - loss: 0.4072 - val_accuracy: 0.9333 - val_loss: 0.3167\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8806 - loss: 0.3875 - val_accuracy: 0.9333 - val_loss: 0.3134\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9150 - loss: 0.3570 - val_accuracy: 0.9333 - val_loss: 0.3100\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8775 - loss: 0.4042 - val_accuracy: 0.9333 - val_loss: 0.3067\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8817 - loss: 0.3919 - val_accuracy: 0.9333 - val_loss: 0.3034\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8712 - loss: 0.3628 - val_accuracy: 0.9333 - val_loss: 0.3002\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8796 - loss: 0.3711 - val_accuracy: 0.9333 - val_loss: 0.2969\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9160 - loss: 0.3160 - val_accuracy: 0.9333 - val_loss: 0.2936\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8702 - loss: 0.3656 - val_accuracy: 0.9333 - val_loss: 0.2905\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8619 - loss: 0.3711 - val_accuracy: 0.9333 - val_loss: 0.2874\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8900 - loss: 0.3600 - val_accuracy: 0.9333 - val_loss: 0.2844\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9098 - loss: 0.3174 - val_accuracy: 0.9333 - val_loss: 0.2812\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8952 - loss: 0.3449 - val_accuracy: 0.9333 - val_loss: 0.2783\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9046 - loss: 0.3341 - val_accuracy: 0.9333 - val_loss: 0.2755\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9223 - loss: 0.3065 - val_accuracy: 0.9333 - val_loss: 0.2727\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8817 - loss: 0.3595 - val_accuracy: 0.9333 - val_loss: 0.2700\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8869 - loss: 0.3391 - val_accuracy: 0.9333 - val_loss: 0.2673\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8650 - loss: 0.3569 - val_accuracy: 0.9333 - val_loss: 0.2647\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9129 - loss: 0.2907 - val_accuracy: 0.9333 - val_loss: 0.2619\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.3196 - val_accuracy: 0.9333 - val_loss: 0.2593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9333 - loss: 0.2593\n",
      "Test Loss : 0.25933992862701416, Test Accuracy : 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(4,)))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss : {loss}, Test Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9b0fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "[[6.25119582e-02 7.12807059e-01 2.24680990e-01]\n",
      " [9.41969514e-01 5.17152324e-02 6.31522341e-03]\n",
      " [7.33797788e-05 7.68277869e-02 9.23098803e-01]\n",
      " [5.81293553e-02 4.56633568e-01 4.85237092e-01]\n",
      " [1.69113092e-02 6.77998245e-01 3.05090457e-01]\n",
      " [8.95318508e-01 9.35921818e-02 1.10893073e-02]\n",
      " [2.97164440e-01 5.12432158e-01 1.90403372e-01]\n",
      " [2.49779900e-03 1.43440336e-01 8.54061902e-01]\n",
      " [2.20164433e-02 8.16482961e-01 1.61500633e-01]\n",
      " [1.33827090e-01 7.12432742e-01 1.53740123e-01]\n",
      " [9.10458248e-03 1.78134069e-01 8.12761307e-01]\n",
      " [8.47229540e-01 1.47516385e-01 5.25404420e-03]\n",
      " [9.07573342e-01 8.58110338e-02 6.61557214e-03]\n",
      " [8.70597184e-01 1.24138482e-01 5.26430365e-03]\n",
      " [9.82294798e-01 1.46545712e-02 3.05069564e-03]\n",
      " [4.85574715e-02 3.01073283e-01 6.50369227e-01]\n",
      " [2.32152757e-03 1.08359374e-01 8.89319062e-01]\n",
      " [1.16343766e-01 7.82548368e-01 1.01107836e-01]\n",
      " [1.08371474e-01 6.05917096e-01 2.85711497e-01]\n",
      " [2.36789207e-03 1.09344363e-01 8.88287783e-01]\n",
      " [9.34820831e-01 6.06985651e-02 4.48062038e-03]\n",
      " [1.83825567e-02 2.13309497e-01 7.68307984e-01]\n",
      " [9.48073864e-01 4.48437817e-02 7.08237989e-03]\n",
      " [2.81371945e-03 1.20433830e-01 8.76752436e-01]\n",
      " [1.39051827e-03 2.64039010e-01 7.34570503e-01]\n",
      " [2.50448915e-03 1.30067080e-01 8.67428422e-01]\n",
      " [3.68848071e-03 3.85314703e-01 6.10996783e-01]\n",
      " [1.67825609e-03 1.02492265e-01 8.95829558e-01]\n",
      " [8.55377257e-01 1.36536583e-01 8.08611885e-03]\n",
      " [8.90164435e-01 1.04002155e-01 5.83345443e-03]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d04985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.78      0.88         9\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.95      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 보고서 출력\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf889cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 그리기\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
