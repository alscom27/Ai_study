{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157143d7",
   "metadata": {},
   "source": [
    "### Pytorch Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192d6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a815868",
   "metadata": {},
   "source": [
    "### 모델 정의(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92385522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape=(3, 64, 64), # 입력 이미지 크기(채널, 높이, 너비)\n",
    "                 num_classes=10, # 출력 클래스 수\n",
    "                 depth=2, # Conv 블록 개수 (예: 2->경량, 4->고성능(더 깊어짐))\n",
    "                 base_channels=32, # 첫 Conv 블록의 출력 채널 수\n",
    "                 activation='relu', # 활성화 함수 선택(relu, gelu, leaky_relu, sigmoid, 등)\n",
    "                 kernel_size=3, # Conv 필터 크기\n",
    "                 dropout_rate=0.25, # Conv 블록 내 Dropout 비율\n",
    "                 padding='same', # 패딩 모드 : same, valid, 정수 등\n",
    "                 use_batchnorm=False # 배치 정규화 사용 여부\n",
    "                 ):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # 활성화 함수 매핑 (클래스 기반)\n",
    "        activation_map = {\n",
    "            'relu' : nn.ReLU,\n",
    "            'leaky_relu' : nn.LeakyReLU,\n",
    "            'gelu' : nn.GELU,\n",
    "            'tanh' : nn.Tanh,\n",
    "            'sigmoid' : nn.Sigmoid\n",
    "        }\n",
    "        \n",
    "        if activation not in activation_map:\n",
    "            raise ValueError(f\"Unsupported activation : {activation}. Choose from {list(activation_map.keys())}\")\n",
    "        self.activation_cls = activation_map[activation]\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2) #\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = input_shape[0]\n",
    "        \n",
    "        for i in range(depth):\n",
    "            out_channels = base_channels * (2**i)\n",
    "            #\n",
    "            pad = self.resolve_padding(padding, kernel_size)\n",
    "            \n",
    "            # 첫 번째 Conv block\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=pad))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(self.activation_cls())\n",
    "            \n",
    "            # 두 번째 ~ Conv block\n",
    "            if i < depth -1 :\n",
    "                layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=pad))\n",
    "                if use_batchnorm:\n",
    "                    layers.append(nn.BatchNorm2d(out_channels))\n",
    "                layers.append(self.activation_cls())\n",
    "                \n",
    "            # 풀링 + 드롭아웃\n",
    "            layers.append(self.pool)\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "                \n",
    "        # Flatten 크기 자동 계산\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, *input_shape)\n",
    "            x = self.conv_block(dummy)\n",
    "            self.flatten_dim = x.view(1, -1).shape[1]\n",
    "            \n",
    "        # Fully-connected Layer\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flatten_dim, 128),\n",
    "            self.activation_cls(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    # 패딩 계산 함수\n",
    "    @staticmethod\n",
    "    def resolve_padding(padding, kernel_size):\n",
    "        if isinstance(padding, str):\n",
    "            if padding.lower() == 'same':\n",
    "                if isinstance(kernel_size, int):\n",
    "                    return kernel_size // 2\n",
    "                elif isinstance(kernel_size, tuple):\n",
    "                    return tuple(k // 2 for k in kernel_size)\n",
    "            elif padding.lower() == 'valid':\n",
    "                return 0\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported padding String : {padding}\")\n",
    "        elif isinstance(padding, int):\n",
    "            return padding\n",
    "        elif isinstance(padding, tuple):\n",
    "            return padding\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported padding type : {type(padding)}\")\n",
    "    # /패딩 계산 함수\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc\n",
    "        _layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af1a42",
   "metadata": {},
   "source": [
    "### 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cf9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train() # 모델을 학습 모드로 전환\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. 순전파\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. 손실 계산\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # 4. 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. 파라키터 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계 기록\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # 에측 결과\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    print(f\"Train Loss : {epoch_loss:.4f}, Accuracy : {epoch_acc:.4f}\")\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d11190",
   "metadata": {},
   "source": [
    "### 전체 학습 루프 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff226a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, loss_fn, optimizer, device, epochs=10):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7545b",
   "metadata": {},
   "source": [
    "### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aaba7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 모델 , 손실 함수, 옵티마이저 정의 \n",
    "\n",
    "# 1. 모델 정의\n",
    "model = CustomCNN(\n",
    "    input_shape=(3, 64, 64),\n",
    "    num_classes=10,\n",
    "    depth=3,\n",
    "    base_channels=32,\n",
    "    activation='relu',\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.25,\n",
    "    padding='same',\n",
    "    use_batchnorm=True\n",
    ")\n",
    "\n",
    "# 2. GPU 사용 가능하면 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. 옵티마이저 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09598a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
