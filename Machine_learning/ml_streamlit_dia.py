# -------------------------- ê¸°ì¡´ ì½”ë“œ ìƒë‹¨ + ìˆ˜ì • -------------------------------
import streamlit as st
import numpy as np
import pandas as pd
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# matplotlib í•œê¸€ ê¹¨ì§ ë°©ì§€
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

st.set_page_config(layout="wide")

# -------------------------- ë°ì´í„° ë¡œë“œ ë° ë¶„í•  -------------------------------
data = load_diabetes(as_frame=True)
df = data.frame
X = df.drop("target", axis=1)
y = df["target"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

st.title("ğŸ§ª ë‹¹ë‡¨ë³‘ ì§„í–‰ ì˜ˆì¸¡ - íšŒê·€ ëª¨ë¸ í•™ìŠµ ì•±")
st.markdown(
    """
ì´ ì•±ì€ **ì„ í˜• íšŒê·€ ëª¨ë¸**ì„ í•™ìŠµí•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ **ëª¨ë¸ì„ í•´ì„í•˜ê³  ì´í•´í•˜ëŠ” í•™ìŠµìš© ë„êµ¬**ì…ë‹ˆë‹¤.
- ë‹¤ì–‘í•œ íšŒê·€ ëª¨ë¸ì„ ì„ íƒí•˜ê³ ,  
- ë°ì´í„°ë¥¼ í•™ìŠµí•œ í›„,  
- ì˜ˆì¸¡ ì„±ëŠ¥ê³¼ ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
)

# -------------------------- ëª¨ë¸ ì„ íƒ -------------------------------
model_name = st.selectbox(
    "ğŸ” íšŒê·€ ëª¨ë¸ ì„ íƒ", ["Lasso", "Ridge", "Elastic Net", "Polynomial Regression"]
)


# -------------------------- ëª¨ë¸ ì„¤ëª… -------------------------------
def show_model_description(name):
    with st.expander("ğŸ“˜ ì„ íƒí•œ ëª¨ë¸ ì„¤ëª…"):
        if name == "Lasso":
            st.markdown(
                "**Lasso íšŒê·€**ëŠ” L1 ì •ê·œí™”ë¥¼ ì‚¬ìš©í•´ ì¼ë¶€ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë³€ìˆ˜ ì„ íƒ íš¨ê³¼ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
            )
            st.latex(r"J(\theta) = \sum(y_i - \hat{y}_i)^2 + \lambda \sum|\theta_j|")
        elif name == "Ridge":
            st.markdown(
                "**Ridge íšŒê·€**ëŠ” L2 ì •ê·œí™”ë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ê³„ìˆ˜ë¥¼ ì‘ê²Œ ìœ ì§€ì‹œí‚µë‹ˆë‹¤."
            )
            st.latex(r"J(\theta) = \sum(y_i - \hat{y}_i)^2 + \lambda \sum\theta_j^2")
        elif name == "Elastic Net":
            st.markdown(
                "**Elastic Net**ì€ L1 + L2ë¥¼ ê²°í•©í•´ ë³€ìˆ˜ ì„ íƒê³¼ ì •ê·œí™”ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤."
            )
            st.latex(
                r"J(\theta) = \sum(y_i - \hat{y}_i)^2 + \alpha(\lambda_1 \sum|\theta_j| + \lambda_2 \sum\theta_j^2)"
            )
        elif name == "Polynomial Regression":
            st.markdown(
                "**ë‹¤í•­ íšŒê·€**ëŠ” ì…ë ¥ ë³€ìˆ˜ë¥¼ ê±°ë“­ì œê³±í•˜ì—¬ ë¹„ì„ í˜• ê´€ê³„ë¥¼ ì„ í˜• íšŒê·€ë¡œ í•™ìŠµí•©ë‹ˆë‹¤."
            )
            st.latex(
                r"\hat{y} = \theta_0 + \theta_1x + \theta_2x^2 + ... + \theta_nx^n"
            )


show_model_description(model_name)

# -------------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • -------------------------------
if model_name == "Polynomial Regression":
    degree = st.slider("ë‹¤í•­ì‹ ì°¨ìˆ˜ ì„ íƒ", 1, 5, 2)
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)
    model = LinearRegression()
else:
    X_train_poly = X_train
    X_test_poly = X_test
    alpha = st.slider("ì •ê·œí™” ê°•ë„ (ì•ŒíŒŒ ê°’)", 0.001, 10.0, 1.0, 0.001)
    if model_name == "Lasso":
        model = Lasso(alpha=alpha)
    elif model_name == "Ridge":
        model = Ridge(alpha=alpha)
    elif model_name == "Elastic Net":
        l1_ratio = st.slider("L1 ë¹„ìœ¨", 0.1, 0.9, 0.5, 0.1)
        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)

# -------------------------- ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ -------------------------------
model.fit(X_train_poly, y_train)
y_pred = model.predict(X_test_poly)

# -------------------------- ì„±ëŠ¥ í‰ê°€ -------------------------------
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

st.markdown("### ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
st.markdown(
    f"""
- **RÂ² (ì„¤ëª…ë ¥)**: {r2:.4f} â†’ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ  
- **RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)**: {rmse:.4f} â†’ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì°¨ì´ì˜ í‘œì¤€í¸ì°¨  
- **MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)**: {mae:.4f} â†’ ì§ê´€ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ í‰ê·  ì˜ˆì¸¡ ì˜¤ì°¨
"""
)

# -------------------------- ì˜ˆì¸¡ vs ì‹¤ì œ ì‹œê°í™” -------------------------------
col1, col2 = st.columns(2)
with col1:
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.scatterplot(x=y_test, y=y_pred, ax=ax, color="blue", alpha=0.6)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")
    ax.set_title("ì‹¤ì œ ê°’ vs ì˜ˆì¸¡ ê°’")
    ax.set_xlabel("ì‹¤ì œ ê°’")
    ax.set_ylabel("ì˜ˆì¸¡ ê°’")
    st.pyplot(fig)

with col2:
    residuals = y_test - y_pred
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.histplot(residuals, bins=20, kde=True, ax=ax, color="purple")
    ax.set_title("ì”ì°¨ ë¶„í¬ (ì˜¤ì°¨)")
    st.pyplot(fig)

# -------------------------- íšŒê·€ ê³„ìˆ˜ ì‹œê°í™” -------------------------------
if model_name != "Polynomial Regression" or degree <= 2:
    try:
        st.markdown("### ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ (íšŒê·€ ê³„ìˆ˜)")
        coef = model.coef_
        feature_names = (
            poly.get_feature_names_out(X.columns)
            if model_name == "Polynomial Regression"
            else X.columns
        )
        coef_df = pd.Series(coef, index=feature_names).sort_values()
        fig, ax = plt.subplots(figsize=(8, 5))
        coef_df.plot(kind="barh", ax=ax, color="teal")
        ax.set_title("íšŒê·€ ê³„ìˆ˜ í¬ê¸° (í´ìˆ˜ë¡ ì˜í–¥ë ¥ â†‘)")
        st.pyplot(fig)
    except Exception as e:
        st.warning("íšŒê·€ ê³„ìˆ˜ë¥¼ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------- ëª¨ë¸ ë¹„êµ ê¸°ëŠ¥ -------------------------------
st.markdown("## ğŸ”¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜")

if st.checkbox("ğŸ“Š ëª¨ë“  ëª¨ë¸ í•™ìŠµ & ë¹„êµí•˜ê¸°"):
    compare_models = {
        "Lasso": Lasso(alpha=1.0),
        "Ridge": Ridge(alpha=1.0),
        "Elastic Net": ElasticNet(alpha=1.0, l1_ratio=0.5),
        "Polynomial (deg=2)": LinearRegression(),
    }

    r2_list = []
    rmse_list = []

    for name, m in compare_models.items():
        if "Polynomial" in name:
            poly = PolynomialFeatures(degree=2, include_bias=False)
            X_tr = poly.fit_transform(X_train)
            X_te = poly.transform(X_test)
        else:
            X_tr, X_te = X_train, X_test

        m.fit(X_tr, y_train)
        y_pred = m.predict(X_te)

        r2_list.append(r2_score(y_test, y_pred))
        rmse_list.append(np.sqrt(mean_squared_error(y_test, y_pred)))

    result_df = pd.DataFrame(
        {"ëª¨ë¸": list(compare_models.keys()), "RÂ² ì ìˆ˜": r2_list, "RMSE": rmse_list}
    )

    st.markdown("### ğŸ“‹ ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµí‘œ")
    st.dataframe(result_df.style.background_gradient(cmap="YlGnBu", axis=0))

    # ì‹œê°í™” (ê°€ë¡œ)
    col1, col2 = st.columns(2)
    with col1:
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.barplot(x="RÂ² ì ìˆ˜", y="ëª¨ë¸", data=result_df, palette="viridis", ax=ax)
        ax.set_title("ëª¨ë¸ë³„ RÂ² ì ìˆ˜")
        st.pyplot(fig)

    with col2:
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.barplot(x="RMSE", y="ëª¨ë¸", data=result_df, palette="rocket", ax=ax)
        ax.set_title("ëª¨ë¸ë³„ RMSE")
        st.pyplot(fig)
