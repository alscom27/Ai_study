import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import (
    load_iris,
    load_wine,
    load_diabetes,
    load_breast_cancer,
    fetch_california_housing,
)
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    mean_squared_error,
    r2_score,
    ConfusionMatrixDisplay,
)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.ensemble import (
    RandomForestClassifier,
    RandomForestRegressor,
    ExtraTreesClassifier,
    ExtraTreesRegressor,
    BaggingClassifier,
    BaggingRegressor,
    AdaBoostClassifier,
    AdaBoostRegressor,
    GradientBoostingClassifier,
    GradientBoostingRegressor,
    VotingClassifier,
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False


# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸ‘¶ Beginner Model Explorer",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ ì‚¬ì´ë“œë°”: ì„¤ì • ë©”ë‰´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("âš™ï¸ Settings")

# 1) ë°ì´í„°ì…‹ ê³ ë¥´ê¸°
DATASETS = {
    "Iris (ë¶„ë¥˜)": load_iris,
    "Wine (ë¶„ë¥˜)": load_wine,
    "Breast Cancer (ë¶„ë¥˜)": load_breast_cancer,
    "Diabetes (íšŒê·€)": load_diabetes,
    # "House Price (íšŒê·€)": fetch_california_housing,
}
ds_name = st.sidebar.selectbox("1ï¸âƒ£ ë°ì´í„°ì…‹ ì„ íƒ", list(DATASETS.keys()))
loader = DATASETS[ds_name]()
X, y = loader.data, loader.target
feature_names = loader.feature_names
target_names = getattr(loader, "target_names", None)
is_reg = "íšŒê·€" in ds_name

# 2) ëª¨ë¸ ê³ ë¥´ê¸°
st.sidebar.markdown("2ï¸âƒ£ ëª¨ë¸ ì„ íƒ")
ALL_MODELS = {
    "KNN": (KNeighborsRegressor if is_reg else KNeighborsClassifier),
    "SVR": (SVR if is_reg else SVR),
    "Decision Tree": (DecisionTreeRegressor if is_reg else DecisionTreeClassifier),
    "Random Forest": (RandomForestRegressor if is_reg else RandomForestClassifier),
    "Extra Trees": (ExtraTreesRegressor if is_reg else ExtraTreesClassifier),
    "Bagging": (BaggingRegressor if is_reg else BaggingClassifier),
    "AdaBoost": (AdaBoostRegressor if is_reg else AdaBoostClassifier),
    "Gradient Boosting": (
        GradientBoostingRegressor if is_reg else GradientBoostingClassifier
    ),
}
if not is_reg:
    ALL_MODELS["Voting"] = VotingClassifier(
        [
            ("rf", RandomForestClassifier()),
            ("et", ExtraTreesClassifier()),
            ("dt", DecisionTreeClassifier()),
        ],
        voting="hard",
    )
models = st.sidebar.multiselect(
    "ë¹„êµí•  ëª¨ë¸ (ìµœì†Œ 1ê°œ)",
    list(ALL_MODELS.keys()),
    default=list(ALL_MODELS.keys())[:3],
)

# 3) ì •ë ¬ ê¸°ì¤€
st.sidebar.markdown("3ï¸âƒ£ ê²°ê³¼ ì •ë ¬")
sort_by = st.sidebar.selectbox("ì •ë ¬ ê¸°ì¤€", ["Test Score", "Train Score"])
asc = st.sidebar.radio("ì˜¤ë¦„/ë‚´ë¦¼ì°¨ìˆœ", ["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"]) == "ì˜¤ë¦„ì°¨ìˆœ"

# 4) ì‹¤í–‰ ë²„íŠ¼
run = st.sidebar.button("â–¶ï¸ ì‹¤í–‰")

# â”€â”€ ë©”ì¸ í™”ë©´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ‘¶ Beginner Model Explorer")
st.write("**ë‹¨ê³„ë³„ë¡œ ë”°ë¼ê°€ë©° ëª¨ë¸ ì„±ëŠ¥ì„ ì§ê´€ì ìœ¼ë¡œ ë¹„êµí•´ë³´ì„¸ìš”!**")

# â”€â”€ Step 1: ë°ì´í„° ë³´ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ” Step 1. ë°ì´í„° ë¯¸ë¦¬ ë³´ê¸°"):
    st.write(f"- **ë°ì´í„°ì…‹**: `{ds_name}`")
    st.write(f"- **ìƒ˜í”Œ ìˆ˜**: {X.shape[0]}ê°œ, **íŠ¹ì§• ìˆ˜**: {X.shape[1]}ê°œ")
    df = pd.DataFrame(X, columns=feature_names)
    if target_names is not None:
        df["Target"] = [target_names[i] for i in y]
    else:
        df["Target"] = y
    st.dataframe(df.head(), use_container_width=True)

# ì‹¤í–‰ì„ ëˆ„ë¥¸ ë’¤ ì•„ë˜ë¶€í„° ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.
if run and models:
    # â”€â”€ Step 2: Cross-Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## 2ï¸âƒ£ Cross-Validation ê²°ê³¼ ëª¨ìœ¼ê¸°")
    scoring = "r2" if is_reg else "accuracy"
    results_avg = {}
    results_raw = {}

    for name in models:
        Cls = ALL_MODELS[name]
        clf = Cls() if name != "Voting" else ALL_MODELS["Voting"]
        pipe = make_pipeline(StandardScaler(), clf)
        cv = cross_validate(pipe, X, y, cv=5, scoring=scoring, return_train_score=True)
        results_avg[name] = {
            "Test Score": cv["test_score"].mean(),
            "Train Score": cv["train_score"].mean(),
        }
        results_raw[name] = cv["test_score"]

    df_avg = pd.DataFrame(results_avg).T
    df_avg["Std Dev"] = pd.Series({m: np.std(results_raw[m]) for m in models})
    df_avg = df_avg.sort_values(by=sort_by, ascending=asc)

    # â”€â”€ Step 3: ì»¬ëŸ¬ í…Œì´ë¸” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## 3ï¸âƒ£ í‰ê·  ì„±ëŠ¥ ì»¬ëŸ¬ í…Œì´ë¸”")
    st.dataframe(
        df_avg.style.background_gradient(subset=["Test Score"], cmap="Blues").format(
            "{:.4f}"
        ),
        use_container_width=True,
    )

    # â”€â”€ Step 4: Error Bar ê·¸ë˜í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## 4ï¸âƒ£ ì—ëŸ¬ë°” ì°¨íŠ¸ë¡œ ë¹„êµí•˜ê¸°")
    fig, ax = plt.subplots(figsize=(6, 3))
    ax.bar(df_avg.index, df_avg["Test Score"], yerr=df_avg["Std Dev"], capsize=5)
    ax.set_ylabel(scoring.upper())
    ax.set_title("í‰ê·  Test Score Â± í‘œì¤€í¸ì°¨")
    plt.xticks(rotation=45, ha="right")
    st.pyplot(fig)

    # â”€â”€ Step 5: Foldë³„ Boxplot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("## 5ï¸âƒ£ Foldë³„ ë¶„í¬ í™•ì¸")
    fig2, ax2 = plt.subplots(figsize=(6, len(models) * 0.4))
    ax2.boxplot(
        [results_raw[m] for m in df_avg.index], labels=df_avg.index, notch=False
    )
    ax2.set_ylabel(scoring.upper())
    ax2.set_title("5-Fold Test Score ë¶„í¬")
    plt.xticks(rotation=45, ha="right")
    st.pyplot(fig2)

    # â”€â”€ Step 6: íšŒê·€ vs ë¶„ë¥˜ ë³„ ì¶”ê°€ ì‹œê°í™” â”€â”€â”€
    if is_reg:
        st.markdown("## 6ï¸âƒ£ íšŒê·€: ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„")
        X_tr, X_te, y_tr, y_te = train_test_split(
            StandardScaler().fit_transform(X), y, test_size=0.3, random_state=42
        )
        for name in df_avg.index:
            if name == "Voting":
                continue
            model = ALL_MODELS[name]().fit(X_tr, y_tr)
            y_pr = model.predict(X_te)
            fig3, ax3 = plt.subplots(figsize=(4, 3))
            ax3.scatter(y_te, y_pr, alpha=0.5)
            m, b = np.polyfit(y_te, y_pr, 1)
            ax3.plot(y_te, m * y_te + b, color="red")
            ax3.set_title(name)
            ax3.set_xlabel("ì‹¤ì œ ê°’")
            ax3.set_ylabel("ì˜ˆì¸¡ ê°’")
            st.pyplot(fig3)

    else:
        st.markdown("## 6ï¸âƒ£ ë¶„ë¥˜: ìµœìƒìœ„ ëª¨ë¸ í˜¼ë™ í–‰ë ¬")
        # â–¶ train/test split ê²°ê³¼ë¥¼ 4ê°œ ë³€ìˆ˜ë¡œ ë¶„ë¦¬
        X_tr, X_te, y_tr, y_te = train_test_split(
            StandardScaler().fit_transform(X), y, test_size=0.3, random_state=42
        )
        best = df_avg.index[0]
        model = ALL_MODELS[best]().fit(X_tr, y_tr)

        fig4, ax4 = plt.subplots()
        ConfusionMatrixDisplay.from_estimator(
            model, X_te, y_te, display_labels=target_names, ax=ax4
        )
        ax4.set_title(f"{best} í˜¼ë™ í–‰ë ¬")
        st.pyplot(fig4)
